{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb10120d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Assume these are in the current path or installed\n",
    "from evodiff.utils import Tokenizer\n",
    "from evodiff.losses import D3PMLVBLoss, D3PMCELoss\n",
    "# Use your specific sequence constants\n",
    "from sequence_models.constants import PROTEIN_ALPHABET, PAD, MASK, GAP, START, STOP, SEP, MSA_AAS\n",
    "\n",
    "from src.collator import ConditionalD3PMCollator \n",
    "from src.data import ConditionalProteinDataset    \n",
    "from src.model import ConditionalByteNetLMTime\n",
    "from src.generate import generate_conditional_d3pm as generate\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"On device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df05ee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tokens = 28\n",
    "args = {\n",
    "    'data_dir': 'data/',\n",
    "    'train_data': 'train_ec_all.csv',\n",
    "    'valid_data': 'test_ec_all.csv',\n",
    "    'output_dir': 'runs/large',\n",
    "    'd_embed': 8,\n",
    "    'd_model': 1280,\n",
    "    'n_layers': 32,\n",
    "    'kernel_size': 5,\n",
    "    'r': 128,\n",
    "    'class_dropout_prob': 0.1,\n",
    "    'embedding_scale': 1.0,\n",
    "    'slim': False,\n",
    "    'activation': 'gelu',\n",
    "    'diffusion_timesteps': 500,\n",
    "    'reweighting_term': 0.01,\n",
    "    'epochs': 500,\n",
    "    'batch_size': 32,\n",
    "    'max_seq_len': 1024,\n",
    "    'lr': 0.0001,\n",
    "    'warmup_steps': 16000,\n",
    "    'accumulate_grad_batches': 4,\n",
    "    'clip_grad_norm': 1.0,\n",
    "    'log_freq': 50,\n",
    "    'checkpoint_freq_steps': 1000,\n",
    "    'save_latest_only': False,\n",
    "    'resume_checkpoint': None,\n",
    "    'log_to_file': True,\n",
    "    'seed': 42,\n",
    "    'num_workers': 0,\n",
    "    'device': None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47a3afd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = {\n",
    "#     'data_dir': 'data/',\n",
    "#     'train_data': 'train_ec_all.csv',\n",
    "#     'valid_data': 'test_ec_all.csv',\n",
    "#     'output_dir': 'runs/small',\n",
    "#     'd_embed': 8,\n",
    "#     'd_model': 1024,\n",
    "#     'n_layers': 16,\n",
    "#     'kernel_size': 5,\n",
    "#     'r': 128,\n",
    "#     'class_dropout_prob': 0.1,\n",
    "#     'embedding_scale': 1.0,\n",
    "#     'slim': True,\n",
    "#     'activation': 'relu',\n",
    "#     'diffusion_timesteps': 500,\n",
    "#     'reweighting_term': 0.01,\n",
    "#     'epochs': 500,\n",
    "#     'batch_size': 224,\n",
    "#     'max_seq_len': 1024,\n",
    "#     'lr': 0.0001,\n",
    "#     'warmup_steps': 10000,\n",
    "#     'accumulate_grad_batches': 1,\n",
    "#     'clip_grad_norm': 1.0,\n",
    "#     'log_freq': 50,\n",
    "#     'checkpoint_freq_steps': 1000,\n",
    "#     'save_latest_only': False,\n",
    "#     'resume_checkpoint': None,\n",
    "#     'log_to_file': True,\n",
    "#     'seed': 42,\n",
    "#     'num_workers': 0,\n",
    "#     'device': None,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81b68e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sohl-dickstein\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(protein_alphabet=PROTEIN_ALPHABET, pad=PAD, all_aas=MSA_AAS, sequences=True)\n",
    "n_tokens = tokenizer.K + 2\n",
    "\n",
    "Q_prod, Q_t = tokenizer.q_random_schedule(timesteps=500)\n",
    "\n",
    "model = ConditionalByteNetLMTime(\n",
    "    n_tokens=n_tokens,\n",
    "    d_embedding=args['d_embed'],\n",
    "    d_model=args['d_model'],\n",
    "    n_layers=args['n_layers'],\n",
    "    kernel_size=args['kernel_size'],\n",
    "    r=args['r'],\n",
    "    slim=args['slim'],\n",
    "    activation=args['activation'],\n",
    "    n_classes=7,\n",
    "    class_dropout_prob=args['class_dropout_prob'],\n",
    "    embedding_scale=args['embedding_scale'],\n",
    "    timesteps=args['diffusion_timesteps'],\n",
    "    padding_idx=tokenizer.pad_id\n",
    "    ).to(device)\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2c29b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "# load model from .pth\n",
    "checkpoint = torch.load('runs/large/checkpoint_best.pt', weights_only=True, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "print(\"loaded model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40cd7bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/baseline_generated.fasta', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "seq_lens = []\n",
    "for line in lines:\n",
    "    if not line.startswith(\">\"):\n",
    "        seq_lens.append(len(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debbd7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce9bcb7f7ce94011a458bebfecefb28a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating class: 1:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818b766b15624dc793479749c4ae38a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating class: 2:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d43dfc7bd874531a8c3f74a30f8e65e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating class: 3:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0f24fd72f804c63a626f4db0f8cb48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating class: 4:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "604998ac43534121a1eae6096ac21988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating class: 5:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "classes = range(1, 8)\n",
    "\n",
    "for label in classes:\n",
    "    untokenized_seqs = []\n",
    "\n",
    "    for length in tqdm(seq_lens[:50], desc=f\"Generating class: {label}\"):\n",
    "        torch.manual_seed(length * (label) + length)\n",
    "        sequences, untokenized = generate(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        Q=Q_t,\n",
    "        Q_bar=Q_prod,\n",
    "        timesteps=500,           # Should match model's training timesteps\n",
    "        seq_len=length,            # Desired sequence length\n",
    "        class_labels=label,         # Which class to condition on (1 to n_classes)\n",
    "        guidance_scale=3.0,     # Higher values = stronger conditioning\n",
    "        batch_size=1,           # Generate 5 sequences at once\n",
    "        device='cuda'\n",
    "        )   \n",
    "        untokenized_seqs.append(untokenized[0])\n",
    "\n",
    "    with open(f'runs/large/generated_sequences/g3_class{label}.fasta', 'w') as f:\n",
    "        for i, seqs in enumerate(untokenized_seqs):\n",
    "            f.write(f'>sequence_{i}\\n')\n",
    "            f.write(f'{seqs}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d3ade5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
